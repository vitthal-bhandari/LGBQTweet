{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "API_KEY = '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'\n",
    "openai.api_key = API_KEY\n",
    "model_id = 'gpt-3.5-turbo'\n",
    "\n",
    "def classify_text(prompt, max_tokens=2000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"The homophobia definition is the fear, hatred, discomfort with, or mistrust of people who are lesbian, gay, or bisexual. Biphobia is fear, hatred, discomfort, or mistrust, specifically of people who are bisexual. Similarly, transphobia is fear, hatred, discomfort with, or mistrust of people who are transgender, genderqueer. You are a text annotation classifier of text as homophobic, transphobic, anti-lgbqt or neither. Just label the data, it must be homophobic, transphobic, anti-lgbqt or neither (only 1 word)\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        n=1,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    generated_text = response.choices[0].message.content.strip()\n",
    "    return generated_text\n",
    "\n",
    "def process_sentences(data, output_file='labeled_sentences.csv', batch_size=1, input_file='updated_input.csv'):\n",
    "    if not os.path.exists(output_file):\n",
    "        df = pd.DataFrame(columns=['text', 'label'])\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Create a copy of the input DataFrame\n",
    "    updated_input = data.copy()\n",
    "\n",
    "    while not updated_input.empty:\n",
    "        labeled_sentences = []\n",
    "        for _, row in tqdm(updated_input.head(batch_size).iterrows(), file=sys.stdout):\n",
    "            sentence = row['text']\n",
    "            print(f\"Processing sentence: {sentence}\")\n",
    "            prompt = f\"Classify the following sentence: \\\"{sentence}\\\"\"\n",
    "            label = classify_text(prompt, max_tokens=200)\n",
    "            labeled_sentences.append({'text': sentence, 'label': label})\n",
    "\n",
    "            # Remove the processed sentence from the updated_input DataFrame\n",
    "            updated_input = updated_input[updated_input['text'] != sentence].reset_index(drop=True)\n",
    "\n",
    "        # Save the updated input DataFrame to a new file\n",
    "        updated_input.to_csv(input_file, index=False)\n",
    "\n",
    "        # Read existing CSV file\n",
    "        df_existing = pd.read_csv(output_file)\n",
    "\n",
    "        # Concatenate new labeled sentences with the existing ones\n",
    "        df_new = pd.DataFrame(labeled_sentences)\n",
    "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "\n",
    "        # Remove duplicates\n",
    "        df_combined.drop_duplicates(subset=['text'], inplace=True)\n",
    "        df_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Save the updated DataFrame to the CSV file\n",
    "        df_combined.to_csv(output_file, index=False)\n",
    "\n",
    "    # Check if the total row count is consistent\n",
    "    original_row_count = len(data)\n",
    "    updated_input_row_count = len(pd.read_csv(input_file))\n",
    "    saved_output_row_count = len(pd.read_csv(output_file))\n",
    "\n",
    "    assert original_row_count == updated_input_row_count + saved_output_row_count, \"Row count mismatch detected.\"\n",
    "\n",
    "def main(input_dataframe, output_file='labeled_sentences.csv', batch_size=1):\n",
    "    print(\"Starting to process sentences...\")\n",
    "    process_sentences(input_dataframe, output_file=output_file, batch_size=batch_size)\n",
    "    print(\"Finished processing sentences.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the original or updated input DataFrame\n",
    "    input_file = 'updated_input.csv'\n",
    "\n",
    "    if os.path.exists(input_file):\n",
    "        input_dataframe = pd.read_csv(input_file)\n",
    "    else:\n",
    "        input_dataframe = pd.read_csv('sentences.csv')\n",
    "        input_dataframe.reset_index(inplace=True)\n",
    "\n",
    "    try:\n",
    "        main(input_dataframe)\n",
    "        print(\"Sentences have been labeled and saved to labeled_sentences.csv.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}. Process stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
